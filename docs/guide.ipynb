{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFCI (Regular Expressions For Class Instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFCI let you use regular expressions for class instances (objects) in Python, using a syntax similar (but not identical) to CQL or Tregex.  It has features on its own.\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "Let's say that you have a list of tokens, each token being an object, with\n",
    "* the form (`form`),\n",
    "* the part of speech (`pos`),\n",
    "* the length of the form (`length`):\n",
    "\n",
    "```python\n",
    "tokens = [\n",
    "    Token('The',    'determiner',   3),\n",
    "    Token('little', 'adjective',    6),\n",
    "    Token('cats',   'noun',         4),\n",
    "    Token('eat',    'verb',         3),\n",
    "    Token('a',      'determiner',   1),\n",
    "    Token('fish',   'noun',         4),\n",
    "    Token('.',      'punctuation',  1),\n",
    "]\n",
    "```\n",
    "\n",
    "Then you can search patterns:\n",
    "* a noun: `[pos=\"noun\"]`\n",
    "* a noun with more than 3 characters: `[pos=\"noun\" length>3]`\n",
    "* a noun beginning with a `c`: ``[pos=\"noun\" form=/c.*/]`\n",
    "* a noun with a determiner before it: `[pos=\"determiner\"][pos=\"noun\"]`\n",
    "* a noun phrase with a determiner, then 0, 1 or more adjectives, then a noun: `[pos=\"determiner\"][pos=\"adjective\"]*[pos=\"noun\"]`\n",
    "* and much, much more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ul><li><a href=\"#REFCI-(Regular-Expressions-For-Class-Instances)\">REFCI (Regular Expressions For Class Instances)</a></li><li><a href=\"#Quick-start\">Quick start</a></li><ul><li><a href=\"#Setup\">Setup</a></li><li><a href=\"#Simple-patterns\">Simple patterns</a></li><li><a href=\"#Variables\">Variables</a></li><li><a href=\"#Groups\">Groups</a></li><li><a href=\"#Quantifiers\">Quantifiers</a></li><li><a href=\"#finditer-vs-search-vs-[full]match\">`finditer` vs `search` vs `[full]match`</a></li></ul><li><a href=\"#Detailed-guide\">Detailed guide</a></li><ul><li><a href=\"#Test-sets\">Test sets</a></li><li><a href=\"#Pattern\">Pattern</a></li><ul><li><a href=\"#Specifications\">Specifications</a></li><li><a href=\"#Quantifiers\">Quantifiers</a></li><li><a href=\"#Groups\">Groups</a></li><li><a href=\"#Examples\">Examples</a></li></ul><li><a href=\"#Match-and-search-functions\">Match and search functions</a></li><li><a href=\"#Returning-indices-or-objects\">Returning indices or objects</a></li><li><a href=\"#Groups\">Groups</a></li><li><a href=\"#Special-behavior-of-group-quantifiers\">Special behavior of group quantifiers</a></li><li><a href=\"#OR-group\">OR group</a></li><li><a href=\"#Using-subpatterns\">Using subpatterns</a></li><li><a href=\"#Using-variable\">Using variable</a></li><li><a href=\"#Using-regex\">Using regex</a></li></ul></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "var = \"\"\"<ul><li><a href=\"#REFCI-(Regular-Expressions-For-Class-Instances)\">REFCI (Regular Expressions For Class Instances)</a></li><li><a href=\"#Quick-start\">Quick start</a></li><ul><li><a href=\"#Setup\">Setup</a></li><li><a href=\"#Simple-patterns\">Simple patterns</a></li><li><a href=\"#Variables\">Variables</a></li><li><a href=\"#Groups\">Groups</a></li><li><a href=\"#Quantifiers\">Quantifiers</a></li><li><a href=\"#finditer-vs-search-vs-[full]match\">`finditer` vs `search` vs `[full]match`</a></li></ul><li><a href=\"#Detailed-guide\">Detailed guide</a></li><ul><li><a href=\"#Test-sets\">Test sets</a></li><li><a href=\"#Pattern\">Pattern</a></li><ul><li><a href=\"#Specifications\">Specifications</a></li><li><a href=\"#Quantifiers\">Quantifiers</a></li><li><a href=\"#Groups\">Groups</a></li><li><a href=\"#Examples\">Examples</a></li></ul><li><a href=\"#Match-and-search-functions\">Match and search functions</a></li><li><a href=\"#Returning-indices-or-objects\">Returning indices or objects</a></li><li><a href=\"#Groups\">Groups</a></li><li><a href=\"#Special-behavior-of-group-quantifiers\">Special behavior of group quantifiers</a></li><li><a href=\"#OR-group\">OR group</a></li><li><a href=\"#Using-subpatterns\">Using subpatterns</a></li><li><a href=\"#Using-variable\">Using variable</a></li><li><a href=\"#Using-regex\">Using regex</a></li></ul></ul>\"\"\"\n",
    "display(HTML(toc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a Token class with a named tuple.  The class has the following attributs:\n",
    "* `form`,\n",
    "* `lemma`,\n",
    "* `pos` (part of speech),\n",
    "* `is_upper` (whether the form starts with an upper case letter),\n",
    "* `length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats\n",
      "cat\n",
      "noun\n",
      "False\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Token = namedtuple('Token', 'form lemma pos is_upper length')\n",
    "\n",
    "token = Token(\"cats\" , \"cat\", \"noun\", False, 4)\n",
    "print(token.form)\n",
    "print(token.lemma)\n",
    "print(token.pos)\n",
    "print(token.is_upper)\n",
    "print(token.length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build some sentences, in the form of a `list` of `Token`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\n",
    "    Token('The',    'the',      'determiner',   True,   3),\n",
    "    Token('little', 'little',   'adjective',    False,  6),\n",
    "    Token('cats',   'cat',      'noun',         False,  4),\n",
    "    Token('eat',    'eat',      'verb',         False,  3),\n",
    "    Token('a',      'a',        'determiner',   False,  1),\n",
    "    Token('fish',   'fish',     'noun',         False,  4),\n",
    "    Token('.',      '.',        'punctuation',  False,  1),\n",
    "    Token('They',   'they',     'pronoun',      True,   4),\n",
    "    Token('are',    'be',       'verb',         False,  3),\n",
    "    Token('happy',  'happy',    'adjective',    False,  5),\n",
    "    Token(':',      ':',        'punctuation',  False,  1),\n",
    "    Token('they',   'they',     'pronoun',      False,  4),\n",
    "    Token('like',   'like',     'verb',         False,  4),\n",
    "    Token('this',   'this',     'determiner',   False,  4),\n",
    "    Token('Meal',   'meal',     'noun',         True,  4),\n",
    "    Token('.',      '.',        'punctuation',  False,  1),\n",
    "    Token('.',      '.',        'punctuation',  False,  1),\n",
    "    Token('.',      '.',        'punctuation',  False,  1),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import `refci` `Pattern` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from refci import Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can start search for patterns.  To build a pattern, just use:\n",
    "\n",
    "```python\n",
    "pat = Pattern('[pos=\"determiner\"][pos=\"noun\"]')\n",
    "```\n",
    "\n",
    "There are 4 main functions you can use:\n",
    "* `pat.search(tokens)`: find the first occurrence of the pattern in the tokens,\n",
    "* `pat.match(tokens)`: the pattern must be at the beginning of the tokens,\n",
    "* `pat.fullmatch(tokens)`: the pattern must match the whole set of tokens\n",
    "* `pat.finditer(tokens)`: loop over all the patterns that match in the tokens (by default not overlapping)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, two find all the **determiners followed by a noun**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'fish']\n",
      "['this', 'Meal']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"determiner\"][pos=\"noun\"]')\n",
    "for seq in pat.finditer(tokens):\n",
    "    print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that `seq` is a `list` of tokens. You can get **position indices** if you prefer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6)\n",
      "(13, 15)\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"determiner\"][pos=\"noun\"]')\n",
    "for seq in pat.finditer(tokens, return_objects=False):\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the determiner must have **less than 4 characters**, just add a condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'fish']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"determiner\" length<4][pos=\"noun\"]')\n",
    "for seq in pat.finditer(tokens):\n",
    "    print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the **noun must be capitalized**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'Meal']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"determiner\"][pos=\"noun\" is_upper=True]')\n",
    "for seq in pat.finditer(tokens):\n",
    "    print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the noun must have a specific lemma, **determined with a regular expression**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'little', 'cats']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"determiner\"][]*?[pos=\"noun\" lemma=/cats?/]')\n",
    "for seq in pat.finditer(tokens):\n",
    "    print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want noun phrase with a determiner and a noun, and **0 or 1 adjective in the middle**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'little', 'cats']\n",
      "['a', 'fish']\n",
      "['this', 'Meal']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"determiner\"][pos=\"adjective\"]?[pos=\"noun\"]')\n",
    "for seq in pat.finditer(tokens):\n",
    "    print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, really, **any word in the middle**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'little', 'cats']\n",
      "['a', 'fish']\n",
      "['this', 'Meal']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"determiner\"][]*?[pos=\"noun\"]')\n",
    "for seq in pat.finditer(tokens):\n",
    "    print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define **variables**.  For example, if you want to search for contiguous words of the same length (even if overlapping):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they', 'like']\n",
      "['like', 'this']\n",
      "['this', 'Meal']\n",
      "['.', '.']\n",
      "['.', '.']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[variable<-length][length==$variable]')\n",
    "for seq in pat.finditer(tokens, overlapping=True):\n",
    "    print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or sequence of 2 words in which the second word is longer than the first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'little']\n",
      "['a', 'fish']\n",
      "['.', 'They']\n",
      "['are', 'happy']\n",
      "[':', 'they']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[variable<-length][length>$variable]')\n",
    "for seq in pat.finditer(tokens, overlapping=True):\n",
    "    print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define groups, either to offer **an alternative** (**OR operator**), for example if you want either a full noun phrase or a pronoun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'little', 'cats']\n",
      "['a', 'fish']\n",
      "['They']\n",
      "['they']\n",
      "['this', 'Meal']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('( [pos=\"determiner\"][]*?[pos=\"noun\"] | [pos=\"pronoun\"] )')\n",
    "for seq in pat.finditer(tokens):\n",
    "    print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or to **capture only parts of the pattern**, for example if your only interested in the noun, not the determiner or the adjectives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "['cats']\n",
      "(5, 6)\n",
      "['fish']\n",
      "(14, 15)\n",
      "['Meal']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"determiner\"][]*?(?P<interesting>[pos=\"noun\"])')\n",
    "for _ in pat.finditer(tokens):\n",
    "    group_indices = pat.get_group('interesting')\n",
    "    print(group_indices)\n",
    "    group_tokens = pat.get_group('interesting', objs=tokens)\n",
    "    print([token.form for token in group_tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the quantifiers familiar to any regular expression engine. For example, with **no quantifier** after the ponctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fish', '.']\n",
      "['Meal', '.']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"noun\"][pos=\"punctuation\"]')\n",
    "for seq in pat.finditer(tokens):\n",
    "    print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with a `*` (0, 1 or more punctuation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats']\n",
      "['fish', '.']\n",
      "['Meal', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"noun\"][pos=\"punctuation\"]*')\n",
    "for seq in pat.finditer(tokens):\n",
    "    print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with a `?` (0 or 1 punctuation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats']\n",
      "['fish', '.']\n",
      "['Meal', '.']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"noun\"][pos=\"punctuation\"]?')\n",
    "for seq in pat.finditer(tokens):\n",
    "    print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with a `+` (1 or more punctuations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fish', '.']\n",
      "['Meal', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"noun\"][pos=\"punctuation\"]+')\n",
    "for seq in pat.finditer(tokens):\n",
    "    print([token.form for token in seq])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with a custom number of punctuation (here between 2 and 3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Meal', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"noun\"][pos=\"punctuation\"]{2,3}')\n",
    "for seq in pat.finditer(tokens):\n",
    "    print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `finditer` vs `search` vs `[full]match`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than `finditer`, you can use `search` to get the first occurrence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"noun\"]')\n",
    "seq = pat.search(tokens)\n",
    "print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the first occurrence after a certain point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Meal']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"noun\"]')\n",
    "seq = pat.search(tokens, start=10)\n",
    "print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `match` function will only match at the beginning of the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'little']\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"determiner\"][pos=\"adjective\"]')\n",
    "seq = pat.match(tokens)\n",
    "print([token.form for token in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the `fullmatch` will only match for the whole token sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[pos=\"determiner\"][pos=\"adjective\"]')\n",
    "seq = pat.fullmatch(tokens)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from refci import Pattern, make_test_data, make_test_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test sets\n",
    "\n",
    "REFCI needs a list of objects. Lets define some objets with two attributes:\n",
    "* `data`: a lower case letter,\n",
    "* `upper`: True if the letter should be rendered has uppercase.\n",
    "\n",
    "There is a function to quickly make this kind of objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: a, upper: False\n",
      "data: b, upper: True\n",
      "data: c, upper: False\n",
      "data: d, upper: True\n"
     ]
    }
   ],
   "source": [
    "objs = make_test_data(\"aBcD\")\n",
    "print(\"\\n\".join(\"data: %s, upper: %s\" % (obj.data, str(obj.upper)) for obj in objs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the same function to define simple patterns, using only letters: `(a+b|f.)`.  This will build the pattern as `([data=\"a\"]+[data=\"b\"]|[data=\"f\"][])`.\n",
    "\n",
    "If you want a more complex pattern, you must define it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: a, upper: False\n",
      "data: b, upper: True\n",
      "data: c, upper: False\n",
      "data: d, upper: True\n",
      "(([data=\"a\"]+ [data=\"b\"]) | ([data=\"f\"] []))\n"
     ]
    }
   ],
   "source": [
    "objs, pat = make_test_data(\"aBcD\", \"(a+b|f.)\")\n",
    "print(\"\\n\".join(\"data: %s, upper: %s\" % (obj.data, str(obj.upper)) for obj in objs))\n",
    "print(pat.get_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern\n",
    "\n",
    "A pattern is a sequence of atoms (`[...]`).  Each atom represents a class instances to match against.  To match, the instance must validate a series of constraints expressed as \"specifications\" inside the atom: `[attr1=\"foo\" attr2>5]`.\n",
    "\n",
    "Atoms can be grouped with parentheses, either to define an `OR` operator, or to define a capturing group.\n",
    "\n",
    "Quantifiers can be added to both atoms and groups.\n",
    "\n",
    "### Specifications\n",
    "\n",
    "You can define:\n",
    "* string: `[attr=\"string\"]` or `[attr!=\"string\"]`,\n",
    "* regex: `[attr=/regex/]` or `[attr!=/regex/]`,\n",
    "* number: `[attr==5]` or `[attr!=5]`; you can use these operators: `==, !=, <, >, <=, >=`,\n",
    "* set variable: `[varname<-attr]`\n",
    "* use variable: `[attr==$varname` or `[attr!=$var]`, you can use these operators: `==, !=, <, >, <=, >=`.  Please note that the operator is `==` even for a string,\n",
    "* bool: `[attr=T]` or `[attr!=T]`, the value may be `True, T, true, t, False, F, false, f`,\n",
    "* sub pattern: `[attr={attr1_of_subobject=\"foo\" attr2_of_subobject=/bar/}]`, where `attr` refers to a list of objects that must match the subpattern.  Available operators: `=` (match), `==` (fullmatch), `~` (search), all can be prefixed with `!` to invert the result.\n",
    "\n",
    "When you specify several specifications, as in `[foo=\"bar\" baz=\"truc\"]`, all must matched.  Use groups to emulate an `OR` operator.\n",
    "\n",
    "The no-spec atom `[]` match every instance.\n",
    "\n",
    "### Quantifiers\n",
    "\n",
    "These are standard regex quantifiers:\n",
    "* default: one repetition, lazy\n",
    "* `*`:  0 or more, greedy\n",
    "* `?`:  0 or 1,  greedy\n",
    "* `+`:  1 or more, greedy\n",
    "* `*?`: 0 or more, lazy\n",
    "* `??`: 0 or 1,  lazy\n",
    "* `+?`: 1 or more, lazy\n",
    "* `*+`: 0 or more, possessive\n",
    "* `?+`: 0 or 1,  possessive\n",
    "* `++`: 1 or more, possessive\n",
    "* `{1,2}` (greedy), `{1,2}?` (lazy), `{2,}+` (possessive)\n",
    "\n",
    "### Groups\n",
    "\n",
    "The Python syntax is used:\n",
    "* capturing group: `([][])`\n",
    "* named capturing group: `(?P<name>[][])`\n",
    "* non capturing group: `(?:[][])`\n",
    "* the `OR` operator: `([] | [][] | ([] | [][]) )`\n",
    "\n",
    "### Examples\n",
    "\n",
    "    [attr1=\"foo\" attr2=/.foo/]++ []*? (?P<something> [attr1=\"bar\"] | [attr1=\"baz\"] )\n",
    "    [var<-attr1] []* [attr1==$var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match and search functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sample data and pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([data=\"a\"]+ [data=\"b\"])+\n"
     ]
    }
   ],
   "source": [
    "objs, pat = make_test_data(\n",
    "    'aaababaabc',\n",
    "    '(a+b)+',\n",
    ")\n",
    "print(pat.get_string())\n",
    "def print_res(res):\n",
    "    if res is not None:\n",
    "        print(\"\".join(str(x) for x in res))\n",
    "    else:\n",
    "        print(\"no result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match (the pattern must match at object index 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaababaab\n"
     ]
    }
   ],
   "source": [
    "print_res(pat.match(objs, start=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no result\n"
     ]
    }
   ],
   "source": [
    "print_res(pat.match(objs, start=3)) # no match at index 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search (anywhere in the sequence of objects):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaababaab\n"
     ]
    }
   ],
   "source": [
    "print_res(pat.search(objs, start=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match at `start` and at the end of the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no result\n"
     ]
    }
   ],
   "source": [
    "print_res(pat.fullmatch(objs, start=0)) # no match until the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaababaabc\n"
     ]
    }
   ],
   "source": [
    "print_res(make_test_pattern('(a+b)+c').fullmatch(objs, start=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate, without overlapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n",
      "aa\n"
     ]
    }
   ],
   "source": [
    "for res in make_test_pattern('aa+').finditer(objs, start=0):\n",
    "    print_res(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate, with overlapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n",
      "aa\n",
      "aa\n"
     ]
    }
   ],
   "source": [
    "for res in make_test_pattern('aa+').finditer(objs, start=0, overlapping=True):\n",
    "    print_res(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning indices or objects\n",
    "\n",
    "`Pattern` has an attribute `return_objects`, set to True by default.  If it is True, the above functions return a list of objects.  Otherwise, they return a tuple `(start, stop)` (or None if no match).\n",
    "\n",
    "Each function has a parameter of the same name: if it is None, then the value of the instance attribute is used.  Otherwise, it can be True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 9)\n",
      "aaababaab\n"
     ]
    }
   ],
   "source": [
    "res = pat.search(objs, start=0, return_objects=False)\n",
    "print(res)\n",
    "start, stop = res\n",
    "print_res(objs[start:stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = make_test_data('aaabc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n",
      "abc\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('(?P<one>[data=\"a\"][data=\"b\"]) ([])')\n",
    "pat.search(objs)\n",
    "print(pat.get_group(0)) # the whole match\n",
    "res = pat.get_group(0, objs=objs)\n",
    "print_res(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the group by name or by index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab\n",
      "ab\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "print_res(pat.get_group(1, objs=objs))\n",
    "print_res(pat.get_group('one', objs=objs))\n",
    "print_res(pat.get_group(2, objs=objs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get the `(start, stop)` tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "print(pat.get_group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special behavior of group quantifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions are defined in such a way that the quantifier of the content of group has is more important than the quantifier of the group.  In the following example, the quantifier of the content of the group is lazy, but the quantifier of the group is possessive.  The pattern match only a minimal number of repetition of group:\n",
    "\n",
    "    string: 'aaabababc'\n",
    "    regex: /(a++b??)++/\n",
    "    match: aaa\n",
    "\n",
    "even if we might expect a longer match, like this one:\n",
    "\n",
    "    match: aaababa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test that with perl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\r\n"
     ]
    }
   ],
   "source": [
    "open('/tmp/tmp.sh', 'w').write(\n",
    "\"\"\"\n",
    "my $text = \"aaabababc\";\n",
    "\n",
    "if ($text =~ m/(a++b??)++/) {\n",
    "   print $1, \"\\n\";\n",
    "}\n",
    "\"\"\"\n",
    ")\n",
    "!perl /tmp/tmp.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the `mode` of the pattern, you can put the focus of the group quantifier, and get a longer match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = make_test_data(\n",
    "    'aaababaabc',\n",
    ")\n",
    "def show_diff(pat):\n",
    "    pat.set_group_mode('normal') # default\n",
    "    print_res(pat.match(objs))\n",
    "    pat.set_group_mode('group')\n",
    "    print_res(pat.match(objs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n",
      "aaababaa\n"
     ]
    }
   ],
   "source": [
    "show_diff(make_test_pattern('(a++b??)++'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaababaab\n",
      "aaababaab\n"
     ]
    }
   ],
   "source": [
    "show_diff(make_test_pattern('(a++b?)++'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n",
      "aaa\n"
     ]
    }
   ],
   "source": [
    "show_diff(make_test_pattern('(a++b??)+?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaba\n",
      "aaababaa\n"
     ]
    }
   ],
   "source": [
    "show_diff(make_test_pattern('(a++b??){2,3}+'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaAb\n",
      "ab\n",
      "aab\n",
      "cD\n",
      "ee\n"
     ]
    }
   ],
   "source": [
    "objs, pat = make_test_data(\n",
    "    'aaAbabaabcDeeF',\n",
    "    '((c|e).|a+b)'\n",
    ")\n",
    "for res in pat.finditer(objs):\n",
    "    print_res(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "b\n",
      "b\n",
      "D\n",
      "F\n"
     ]
    }
   ],
   "source": [
    "objs = make_test_data(\n",
    "    'aaAbabcDeeFa',\n",
    ")\n",
    "pat = Pattern('([data=\"f\"] | [data=\"b\"] | [upper=T] )')\n",
    "for res in pat.finditer(objs):\n",
    "    print_res(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using subpatterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([data=\"a\" content={([data=\"c\"] [data=\"d\"])}]++) (1, 3)\n",
      "([data=\"a\" content=={([data=\"c\"] [data=\"d\"])}]++) (1, 2)\n",
      "([data=\"a\" content~{([data=\"c\"] [data=\"d\"])}]++) (1, 3)\n",
      "([data=\"a\" content!={([data=\"c\"] [data=\"d\"])}]++) (0, 1)\n",
      "([data=\"a\" content!=={([data=\"c\"] [data=\"d\"])}]++) (0, 1)\n",
      "([data=\"a\" content!~{([data=\"c\"] [data=\"d\"])}]++) (0, 1)\n",
      "([data=\"b\" content!={([data=\"c\"] [data=\"d\"])}]++) (3, 4)\n",
      "([data=\"b\" content={([data=\"d\"] [data=\"d\"])}]++) None\n",
      "([data=/a|b/ content~{([data=\"c\"] [data=\"d\"])}]++) (1, 4)\n"
     ]
    }
   ],
   "source": [
    "objs = make_test_data(\n",
    "    'aaab',\n",
    ")\n",
    "objs[0].content = make_test_data('ab')\n",
    "objs[1].content = make_test_data('cd')\n",
    "objs[2].content = make_test_data('cdd')\n",
    "objs[3].content = make_test_data('ccddd')\n",
    "\n",
    "patterns = [\n",
    "    '[data=\"a\" content={[data=\"c\"][data=\"d\"]}]++',\n",
    "    '[data=\"a\" content=={[data=\"c\"][data=\"d\"]}]++',\n",
    "    '[data=\"a\" content~{[data=\"c\"][data=\"d\"]}]++',\n",
    "    '[data=\"a\" content!={[data=\"c\"][data=\"d\"]}]++',\n",
    "    '[data=\"a\" content!=={[data=\"c\"][data=\"d\"]}]++',\n",
    "    '[data=\"a\" content!~{[data=\"c\"][data=\"d\"]}]++',\n",
    "    '[data=\"b\" content!={[data=\"c\"][data=\"d\"]}]++',\n",
    "    '[data=\"b\" content={[data=\"d\"][data=\"d\"]}]++',\n",
    "    '[data=/a|b/ content~{[data=\"c\"][data=\"d\"]}]++',\n",
    "]\n",
    "for pat in patterns:\n",
    "    pat = Pattern(pat)\n",
    "    res = pat.search(objs, return_objects=False)\n",
    "    print(pat.get_string(), res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbabcDeeFa\n"
     ]
    }
   ],
   "source": [
    "objs = make_test_data(\n",
    "    'aaAbabcDeeFa',\n",
    ")\n",
    "pat = Pattern('[a<-data upper=T][]+[data==$a]')\n",
    "print_res(pat.search(objs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaAbabcDeeFa\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[a<-upper][]+[upper==$a]')\n",
    "print_res(pat.search(objs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeeF\n"
     ]
    }
   ],
   "source": [
    "pat = Pattern('[a<-upper data=\"d\"][]*[upper==$a]')\n",
    "print_res(pat.search(objs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "objs = make_test_data(\n",
    "    'aaAbabcDeeFa',\n",
    ")\n",
    "pat = Pattern('[upper=T data=/d|a/]')\n",
    "for res in pat.finditer(objs):\n",
    "    print_res(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
